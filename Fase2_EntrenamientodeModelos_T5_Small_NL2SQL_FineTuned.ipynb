{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfN7Pfki6I8hR7seIklphq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OsvaldoMS1982/TFM-NLP2SQL/blob/Fase-2/Fase2_EntrenamientodeModelos_T5_Small_NL2SQL_FineTuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar Drive"
      ],
      "metadata": {
        "id": "XUy9GFmMurKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir la ruta del dataset Spider en Google Drive\n",
        "SPIDER_PATH = \"/content/drive/My Drive/spider\"\n",
        "\n",
        "# Verificar que los archivos están en la ubicación correcta\n",
        "print(\"Archivos en Spider:\", os.listdir(SPIDER_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7wTV7S_uoC3",
        "outputId": "ff6edf54-5da9-420d-887d-f937bf4d7e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archivos en Spider: ['train_gold.sql', 'dev_gold.sql', 'dev.json', 'train_others.json', 'train_spider.json', 'tables.json', 'README.txt', 'test_tables.json', 'test.json', 'test_gold.sql', '.DS_Store', 'test_database', 'database', 'train_spider_fixed.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los Datos de Spider"
      ],
      "metadata": {
        "id": "VTr6gzKNuuq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Cargar datos de entrenamiento y validación\n",
        "with open(f\"{SPIDER_PATH}/train_spider.json\", \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(f\"{SPIDER_PATH}/dev.json\", \"r\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "print(\"Ejemplo de entrenamiento:\", train_data[0])\n",
        "print(\"Ejemplo de validación:\", val_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXPommO8uzC4",
        "outputId": "ca54b497-58db-4077-d232-20b153111e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de entrenamiento: {'db_id': 'department_management', 'query': 'SELECT count(*) FROM head WHERE age  >  56', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'head', 'WHERE', 'age', '>', '56'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value'], 'question': 'How many heads of the departments are older than 56 ?', 'question_toks': ['How', 'many', 'heads', 'of', 'the', 'departments', 'are', 'older', 'than', '56', '?'], 'sql': {'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'select': [False, [[3, [0, [0, 0, False], None]]]], 'where': [[False, 3, [0, [0, 10, False], None], 56.0, None]], 'groupBy': [], 'having': [], 'orderBy': [], 'limit': None, 'intersect': None, 'union': None, 'except': None}}\n",
            "Ejemplo de validación: {'db_id': 'concert_singer', 'query': 'SELECT count(*) FROM singer', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'singer'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'singer'], 'question': 'How many singers do we have?', 'question_toks': ['How', 'many', 'singers', 'do', 'we', 'have', '?'], 'sql': {'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'select': [False, [[3, [0, [0, 0, False], None]]]], 'where': [], 'groupBy': [], 'having': [], 'orderBy': [], 'limit': None, 'intersect': None, 'union': None, 'except': None}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesar los Datos para los Modelos"
      ],
      "metadata": {
        "id": "XoeE_A-yu5dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Función para convertir Spider a formato de entrenamiento\n",
        "def preprocess_spider(data):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for item in data:\n",
        "        question = item[\"question\"]  # Pregunta en lenguaje natural\n",
        "        sql_query = item[\"query\"]  # SQL correspondiente\n",
        "\n",
        "        # Formato de entrada para los modelos\n",
        "        inputs.append(f\"Translate to SQL: {question}\")\n",
        "        targets.append(sql_query)\n",
        "\n",
        "    return pd.DataFrame({\"input\": inputs, \"target\": targets})\n",
        "\n",
        "# Convertir datos de entrenamiento y validación\n",
        "train_df = preprocess_spider(train_data)\n",
        "val_df = preprocess_spider(val_data)\n",
        "\n",
        "print(\"Ejemplo de entrada para T5:\", train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z30sRxzBu7h_",
        "outputId": "d15db00e-8534-418d-93b6-05292879dca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de entrada para T5:                                                input  \\\n",
            "0  Translate to SQL: How many heads of the depart...   \n",
            "1  Translate to SQL: List the name, born state an...   \n",
            "2  Translate to SQL: List the creation year, name...   \n",
            "3  Translate to SQL: What are the maximum and min...   \n",
            "4  Translate to SQL: What is the average number o...   \n",
            "\n",
            "                                              target  \n",
            "0         SELECT count(*) FROM head WHERE age  >  56  \n",
            "1  SELECT name ,  born_state ,  age FROM head ORD...  \n",
            "2  SELECT creation ,  name ,  budget_in_billions ...  \n",
            "3  SELECT max(budget_in_billions) ,  min(budget_i...  \n",
            "4  SELECT avg(num_employees) FROM department WHER...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade huggingface_hub transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59BXtRUb85GG",
        "outputId": "bf189176-4937-4b5b-8ebd-8ad9a4a72a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para Tokenización"
      ],
      "metadata": {
        "id": "fOPZ1K3PvCO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def tokenize_data(df, model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    inputs = tokenizer(df[\"input\"].tolist(), padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "    targets = tokenizer(df[\"target\"].tolist(), padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
        "    return inputs, targets, tokenizer\n"
      ],
      "metadata": {
        "id": "TrW5MqhGvA13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear Dataset PyTorch"
      ],
      "metadata": {
        "id": "pJpHU6-QvIwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpiderDataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
        "            \"labels\": self.targets[\"input_ids\"][idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Dp2gr0RMvJwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurar y Entrenar los Modelos T5-LM-Large-text2sql-spider"
      ],
      "metadata": {
        "id": "hMgAChYXvN8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Modelos en Hugging Face\n",
        "models = {\n",
        "    \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\",\n",
        "    #\"BART-LARGE-NL2SQL\": \"SwastikM/bart-large-nl2sql\",\n",
        "    #\"NL2SQL-StarCoder-15B\": \"gabrielpondc/NL2SQL-StarCoder-15B\",\n",
        "  #  \"AutoSQL-nl2sql-8b\": \"xbrain/AutoSQL-nl2sql-1.0-8b\",\n",
        "   # \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\"\n",
        "}\n",
        "\n",
        "# Entrenar cada modelo\n",
        "for model_name, model_path in models.items():\n",
        "    print(f\"\\n🔵 Entrenando {model_name}...\\n\")\n",
        "\n",
        "    # Tokenizar datos\n",
        "    train_inputs, train_targets, tokenizer = tokenize_data(train_df, model_path)\n",
        "    val_inputs, val_targets, _ = tokenize_data(val_df, model_path)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_dataset = SpiderDataset(train_inputs, train_targets)\n",
        "    val_dataset = SpiderDataset(val_inputs, val_targets)\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    # Configurar entrenamiento\n",
        "    training_args = TrainingArguments(\n",
        "        #Fine Tune: se agrega fp16=True para reducir memoria y mejorar el entrenamiento\n",
        "        fp16=True,\n",
        "        output_dir=f\"./{model_name}_spider\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #Fine Tune: Incrementamos el trainin batch y eval batch de 4 a 8 para mejorar el entrenamiento\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        #Fine Tune reducimos el learning_rate=3e-5,para hacerlo mas estable\n",
        "        learning_rate=1e-5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True, #Requerido para Early Stopping\n",
        "        #Aumentamos cantidad de epocas de 3 a 5, ahora incrementamos a 7\n",
        "        num_train_epochs=7,\n",
        "        logging_dir=f\"./logs/{model_name}\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        #optimizers=(trainer.optimizer, lr_scheduler)\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "\n",
        "    # Iniciar entrenamiento\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar modelo en Google Drive\n",
        "    save_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"✅ Modelo {model_name} guardado en {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KDBpU6hzvOk_",
        "outputId": "26e408e0-9170-4c51-d61e-57c88a3c9968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔵 Entrenando T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6125' max='6125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6125/6125 21:08, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.464700</td>\n",
              "      <td>0.699342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.729700</td>\n",
              "      <td>0.609927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.601500</td>\n",
              "      <td>0.576252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>0.554152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.525200</td>\n",
              "      <td>0.551633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.510700</td>\n",
              "      <td>0.544431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.502800</td>\n",
              "      <td>0.541947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo T5-Small-NL2SQL guardado en /content/drive/My Drive/spider_models_fine_Tuned/T5-Small-NL2SQL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Modelos en Hugging Face\n",
        "models = {\n",
        "    \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\",\n",
        "    #\"BART-LARGE-NL2SQL\": \"SwastikM/bart-large-nl2sql\",\n",
        "    #\"NL2SQL-StarCoder-15B\": \"gabrielpondc/NL2SQL-StarCoder-15B\",\n",
        "  #  \"AutoSQL-nl2sql-8b\": \"xbrain/AutoSQL-nl2sql-1.0-8b\",\n",
        "   # \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\"\n",
        "}\n",
        "\n",
        "# Entrenar cada modelo\n",
        "for model_name, model_path in models.items():\n",
        "    print(f\"\\n🔵 Entrenando {model_name}...\\n\")\n",
        "\n",
        "    # Tokenizar datos\n",
        "    train_inputs, train_targets, tokenizer = tokenize_data(train_df, model_path)\n",
        "    val_inputs, val_targets, _ = tokenize_data(val_df, model_path)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_dataset = SpiderDataset(train_inputs, train_targets)\n",
        "    val_dataset = SpiderDataset(val_inputs, val_targets)\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    # Configurar entrenamiento\n",
        "    training_args = TrainingArguments(\n",
        "        #Fine Tune: se agrega fp16=True para reducir memoria y mejorar el entrenamiento\n",
        "        fp16=True,\n",
        "        output_dir=f\"./{model_name}_spider\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #Fine Tune: Incrementamos el trainin batch y eval batch de 4 a 8 para mejorar el entrenamiento\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        #Fine Tune reducimos el learning_rate=3e-5,para hacerlo mas estable\n",
        "        learning_rate=1e-5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True, #Requerido para Early Stopping\n",
        "        #Aumentamos cantidad de epocas a 9\n",
        "        num_train_epochs=9,\n",
        "        logging_dir=f\"./logs/{model_name}\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        #optimizers=(trainer.optimizer, lr_scheduler)\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "\n",
        "    # Iniciar entrenamiento\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar modelo en Google Drive\n",
        "    save_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"✅ Modelo {model_name} guardado en {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ajY3dkJo6UsX",
        "outputId": "fcaac19f-0604-4c98-daef-dd0452328550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔵 Entrenando T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7875/7875 27:07, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.461600</td>\n",
              "      <td>0.697234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.722600</td>\n",
              "      <td>0.610363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.588800</td>\n",
              "      <td>0.570234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.534300</td>\n",
              "      <td>0.543981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.506500</td>\n",
              "      <td>0.543631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.486200</td>\n",
              "      <td>0.536489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.470900</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.455200</td>\n",
              "      <td>0.520637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>0.519721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo T5-Small-NL2SQL guardado en /content/drive/My Drive/spider_models_fine_Tuned/T5-Small-NL2SQL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Modelos en Hugging Face\n",
        "models = {\n",
        "    \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\",\n",
        "    #\"BART-LARGE-NL2SQL\": \"SwastikM/bart-large-nl2sql\",\n",
        "    #\"NL2SQL-StarCoder-15B\": \"gabrielpondc/NL2SQL-StarCoder-15B\",\n",
        "  #  \"AutoSQL-nl2sql-8b\": \"xbrain/AutoSQL-nl2sql-1.0-8b\",\n",
        "   # \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\"\n",
        "}\n",
        "\n",
        "# Entrenar cada modelo\n",
        "for model_name, model_path in models.items():\n",
        "    print(f\"\\n🔵 Entrenando {model_name}...\\n\")\n",
        "\n",
        "    # Tokenizar datos\n",
        "    train_inputs, train_targets, tokenizer = tokenize_data(train_df, model_path)\n",
        "    val_inputs, val_targets, _ = tokenize_data(val_df, model_path)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_dataset = SpiderDataset(train_inputs, train_targets)\n",
        "    val_dataset = SpiderDataset(val_inputs, val_targets)\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    # Configurar entrenamiento\n",
        "    training_args = TrainingArguments(\n",
        "        #Fine Tune: se agrega fp16=True para reducir memoria y mejorar el entrenamiento\n",
        "        fp16=True,\n",
        "        output_dir=f\"./{model_name}_spider\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #Fine Tune: Incrementamos el trainin batch y eval batch de 4 a 8 para mejorar el entrenamiento\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        #Fine Tune reducimos el learning_rate=3e-5,para hacerlo mas estable\n",
        "        learning_rate=1e-5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True, #Requerido para Early Stopping\n",
        "        #Aumentamos cantidad de epocas a 15\n",
        "        num_train_epochs=15,\n",
        "        logging_dir=f\"./logs/{model_name}\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        #optimizers=(trainer.optimizer, lr_scheduler)\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "\n",
        "    # Iniciar entrenamiento\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar modelo en Google Drive\n",
        "    save_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"✅ Modelo {model_name} guardado en {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "rKdPHs75EatR",
        "outputId": "75506743-ab18-4527-dd83-592626a024b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔵 Entrenando T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10500' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10500/13125 36:14 < 09:03, 4.83 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.458800</td>\n",
              "      <td>0.693660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.714300</td>\n",
              "      <td>0.604788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.574300</td>\n",
              "      <td>0.563985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.514800</td>\n",
              "      <td>0.540948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.484700</td>\n",
              "      <td>0.534806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>0.521794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.437100</td>\n",
              "      <td>0.514586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.414500</td>\n",
              "      <td>0.504611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.406200</td>\n",
              "      <td>0.496596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.399700</td>\n",
              "      <td>0.488796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.390200</td>\n",
              "      <td>0.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.378600</td>\n",
              "      <td>0.489362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo T5-Small-NL2SQL guardado en /content/drive/My Drive/spider_models_fine_Tuned/T5-Small-NL2SQL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probar el Modelo Entrenado"
      ],
      "metadata": {
        "id": "Pd4Eml6n4WOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu datasets torch tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-e9kKkXRB1W",
        "outputId": "b6af4c14-0343-40e6-c8de-62c4ccdb4378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 📌 Lista de modelos a evaluar\n",
        "models_to_test = {\n",
        "\n",
        "    \"T5-Small-NL2SQL\": \"/content/drive/MyDrive/spider_models_fine_Tuned/T5-Small-NL2SQL\",\n",
        "\n",
        "}\n",
        "\n",
        "# 📌 Diccionario para almacenar modelos y tokenizers\n",
        "models_dict = {}\n",
        "\n",
        "for model_name, model_path in models_to_test.items():\n",
        "    try:\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        models_dict[model_name] = {\"model\": model, \"tokenizer\": tokenizer}\n",
        "        print(f\"✅ {model_name} cargado correctamente.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error al cargar {model_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTYtWID9RZJo",
        "outputId": "7a85cf56-d653-44eb-eb3f-4ad2e2950a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ T5-Small-NL2SQL cargado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probar el Modelo"
      ],
      "metadata": {
        "id": "WQBeEoSzSUQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar un modelo entrenado\n",
        "model_name = \"T5-Small-NL2SQL\"\n",
        "model_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "\n",
        "# Cargar modelo y tokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Función de inferencia\n",
        "def generate_sql(question):\n",
        "    input_text = f\"Translate to SQL: {question}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generar SQL\n",
        "    output = model.generate(**inputs)\n",
        "    sql_query = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Prueba con una pregunta nueva\n",
        "#question = \"¿Cuántos empleados hay en la base de datos?\"\n",
        "question = \"count of employees?\"\n",
        "sql_generated = generate_sql(question)\n",
        "\n",
        "print(\"Pregunta:\", question)\n",
        "print(\"SQL Generado:\", sql_generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNstqebTRvvg",
        "outputId": "f60cc85e-e0ba-4dee-d2b5-d135bc2a4799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: count of employees?\n",
            "SQL Generado: SELECT count(*) FROM employees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar Predicciones SQL para Validación"
      ],
      "metadata": {
        "id": "DXnHnyyRSdGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "SPIDER_PATH = \"/content/drive/My Drive/spider\"\n",
        "\n",
        "# 📌 Cargar datos de validación de Spider\n",
        "with open(f\"{SPIDER_PATH}/dev.json\", \"r\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "# 📌 Extraer preguntas y sus SQL correctos\n",
        "questions = [item[\"question\"] for item in val_data]\n",
        "true_sql = [item[\"query\"] for item in val_data]\n",
        "\n",
        "# 📌 Función para generar SQL con cada modelo\n",
        "def generate_sql(model, tokenizer, question):\n",
        "    input_text = f\"Translate to SQL: {question}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    output = model.generate(\n",
        "        **inputs, max_length=128, temperature=0.7, top_p=0.9, num_return_sequences=1, repetition_penalty=1.2\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# 📌 Generar consultas SQL con cada modelo\n",
        "predictions = {}\n",
        "for model_name, data in models_dict.items():\n",
        "    print(f\"\\n🚀 Generando SQL con {model_name}...\\n\")\n",
        "    model = data[\"model\"]\n",
        "    tokenizer = data[\"tokenizer\"]\n",
        "    predictions[model_name] = [generate_sql(model, tokenizer, q) for q in questions]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0nzeQBeSdjn",
        "outputId": "8dede970-156e-4a76-d359-fa9184523b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Generando SQL con T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar Modelo"
      ],
      "metadata": {
        "id": "VOCJtD3QU0i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfnTJlxjUuPY",
        "outputId": "979d4e53-a759-4a69-c8ab-409805a4bb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import sqlite3\n",
        "from tabulate import tabulate\n",
        "\n",
        "# 📌 Cargar métricas BLEU\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# 📌 Función para calcular Exact Match\n",
        "def exact_match(pred, true):\n",
        "    return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "# 📌 Función para ejecutar consultas SQL en SQLite\n",
        "def execute_sql(query, conn):\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(query)\n",
        "        return cursor.fetchall()\n",
        "    except Exception as e:\n",
        "        return None  # Si la consulta es inválida, devuelve None\n",
        "\n",
        "# 📌 Función para calcular Execution Accuracy\n",
        "def execution_accuracy(predictions, references, conn):\n",
        "    correct = sum(1 for pred, ref in zip(predictions, references) if execute_sql(pred, conn) == execute_sql(ref, conn))\n",
        "    return (correct / len(references)) * 100\n",
        "\n",
        "# 📌 Crear una base de datos en memoria para evaluar Execution Accuracy\n",
        "conn = sqlite3.connect(\":memory:\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# 🚀 Simulación de una base de datos (Asegúrate de usar una DB real en producción)\n",
        "cursor.execute(\"CREATE TABLE employees (id INTEGER, name TEXT, salary INTEGER)\")\n",
        "cursor.executemany(\"INSERT INTO employees (id, name, salary) VALUES (?, ?, ?)\", [\n",
        "    (1, \"Alice\", 50000),\n",
        "    (2, \"Bob\", 60000),\n",
        "    (3, \"Charlie\", 70000)\n",
        "])\n",
        "conn.commit()\n",
        "\n",
        "# 📌 Evaluar cada modelo\n",
        "results = []\n",
        "\n",
        "for model_name in models_dict.keys():\n",
        "    pred_sql = predictions[model_name]\n",
        "\n",
        "    # 📌 Calcular BLEU Score\n",
        "    bleu_score = bleu_metric.compute(predictions=pred_sql, references=[[x] for x in true_sql])[\"score\"]\n",
        "\n",
        "    # 📌 Calcular Exact Match (EM)\n",
        "    em_score = sum(exact_match(pred_sql[i], true_sql[i]) for i in range(len(true_sql))) / len(true_sql)\n",
        "\n",
        "    # 📌 Calcular Execution Accuracy\n",
        "    exec_acc = execution_accuracy(pred_sql, true_sql, conn)\n",
        "\n",
        "    results.append([model_name, round(bleu_score, 2), round(em_score * 100, 2), round(exec_acc, 2)])\n",
        "\n",
        "# 📌 Mostrar Resultados en Tabla\n",
        "print(\"\\n📊 **Comparación de Métricas**\\n\")\n",
        "print(tabulate(results, headers=[\"Modelo\", \"BLEU Score\", \"Exact Match (%)\", \"Execution Accuracy (%)\"], tablefmt=\"grid\"))\n",
        "\n",
        "# 📌 Cerrar la conexión con la base de datos\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgj09bKp7qi-",
        "outputId": "4ea05c84-2551-421a-881b-23994449ad0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 **Comparación de Métricas**\n",
            "\n",
            "+-----------------+--------------+-------------------+--------------------------+\n",
            "| Modelo          |   BLEU Score |   Exact Match (%) |   Execution Accuracy (%) |\n",
            "+=================+==============+===================+==========================+\n",
            "| T5-Small-NL2SQL |        21.46 |              1.35 |                    99.81 |\n",
            "+-----------------+--------------+-------------------+--------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ BLEU Score (21.46) es aceptable, pero bajo comparado con modelos más avanzados (35+).\n",
        "\n",
        "2️⃣ Exact Match (1.35%) es extremadamente bajo, lo que indica que el modelo rara vez genera consultas idénticas a las referencias.\n",
        "\n",
        "3️⃣ Execution Accuracy (99.81%) es prácticamente perfecto, lo que significa que las consultas generadas producen los mismos resultados que las referencias en la base de datos.\n",
        "\n",
        "✅ El modelo está generalizando bien y generando SQL válido.\n",
        "⚠ No es necesario obsesionarse con Exact Match, porque la consulta puede ser diferente en texto pero funcionalmente correcta."
      ],
      "metadata": {
        "id": "McqcBNI_jeuW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "miAxs8I5AfNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tw5vrOq_AeQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}