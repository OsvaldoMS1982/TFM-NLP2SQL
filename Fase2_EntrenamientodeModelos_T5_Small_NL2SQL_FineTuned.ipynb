{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfN7Pfki6I8hR7seIklphq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OsvaldoMS1982/TFM-NLP2SQL/blob/Fase-2/Fase2_EntrenamientodeModelos_T5_Small_NL2SQL_FineTuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar Drive"
      ],
      "metadata": {
        "id": "XUy9GFmMurKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir la ruta del dataset Spider en Google Drive\n",
        "SPIDER_PATH = \"/content/drive/My Drive/spider\"\n",
        "\n",
        "# Verificar que los archivos estÃ¡n en la ubicaciÃ³n correcta\n",
        "print(\"Archivos en Spider:\", os.listdir(SPIDER_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7wTV7S_uoC3",
        "outputId": "ff6edf54-5da9-420d-887d-f937bf4d7e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archivos en Spider: ['train_gold.sql', 'dev_gold.sql', 'dev.json', 'train_others.json', 'train_spider.json', 'tables.json', 'README.txt', 'test_tables.json', 'test.json', 'test_gold.sql', '.DS_Store', 'test_database', 'database', 'train_spider_fixed.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los Datos de Spider"
      ],
      "metadata": {
        "id": "VTr6gzKNuuq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Cargar datos de entrenamiento y validaciÃ³n\n",
        "with open(f\"{SPIDER_PATH}/train_spider.json\", \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(f\"{SPIDER_PATH}/dev.json\", \"r\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "print(\"Ejemplo de entrenamiento:\", train_data[0])\n",
        "print(\"Ejemplo de validaciÃ³n:\", val_data[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXPommO8uzC4",
        "outputId": "ca54b497-58db-4077-d232-20b153111e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de entrenamiento: {'db_id': 'department_management', 'query': 'SELECT count(*) FROM head WHERE age  >  56', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'head', 'WHERE', 'age', '>', '56'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value'], 'question': 'How many heads of the departments are older than 56 ?', 'question_toks': ['How', 'many', 'heads', 'of', 'the', 'departments', 'are', 'older', 'than', '56', '?'], 'sql': {'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'select': [False, [[3, [0, [0, 0, False], None]]]], 'where': [[False, 3, [0, [0, 10, False], None], 56.0, None]], 'groupBy': [], 'having': [], 'orderBy': [], 'limit': None, 'intersect': None, 'union': None, 'except': None}}\n",
            "Ejemplo de validaciÃ³n: {'db_id': 'concert_singer', 'query': 'SELECT count(*) FROM singer', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'singer'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'singer'], 'question': 'How many singers do we have?', 'question_toks': ['How', 'many', 'singers', 'do', 'we', 'have', '?'], 'sql': {'from': {'table_units': [['table_unit', 1]], 'conds': []}, 'select': [False, [[3, [0, [0, 0, False], None]]]], 'where': [], 'groupBy': [], 'having': [], 'orderBy': [], 'limit': None, 'intersect': None, 'union': None, 'except': None}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesar los Datos para los Modelos"
      ],
      "metadata": {
        "id": "XoeE_A-yu5dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# FunciÃ³n para convertir Spider a formato de entrenamiento\n",
        "def preprocess_spider(data):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for item in data:\n",
        "        question = item[\"question\"]  # Pregunta en lenguaje natural\n",
        "        sql_query = item[\"query\"]  # SQL correspondiente\n",
        "\n",
        "        # Formato de entrada para los modelos\n",
        "        inputs.append(f\"Translate to SQL: {question}\")\n",
        "        targets.append(sql_query)\n",
        "\n",
        "    return pd.DataFrame({\"input\": inputs, \"target\": targets})\n",
        "\n",
        "# Convertir datos de entrenamiento y validaciÃ³n\n",
        "train_df = preprocess_spider(train_data)\n",
        "val_df = preprocess_spider(val_data)\n",
        "\n",
        "print(\"Ejemplo de entrada para T5:\", train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z30sRxzBu7h_",
        "outputId": "d15db00e-8534-418d-93b6-05292879dca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de entrada para T5:                                                input  \\\n",
            "0  Translate to SQL: How many heads of the depart...   \n",
            "1  Translate to SQL: List the name, born state an...   \n",
            "2  Translate to SQL: List the creation year, name...   \n",
            "3  Translate to SQL: What are the maximum and min...   \n",
            "4  Translate to SQL: What is the average number o...   \n",
            "\n",
            "                                              target  \n",
            "0         SELECT count(*) FROM head WHERE age  >  56  \n",
            "1  SELECT name ,  born_state ,  age FROM head ORD...  \n",
            "2  SELECT creation ,  name ,  budget_in_billions ...  \n",
            "3  SELECT max(budget_in_billions) ,  min(budget_i...  \n",
            "4  SELECT avg(num_employees) FROM department WHER...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade huggingface_hub transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59BXtRUb85GG",
        "outputId": "bf189176-4937-4b5b-8ebd-8ad9a4a72a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FunciÃ³n para TokenizaciÃ³n"
      ],
      "metadata": {
        "id": "fOPZ1K3PvCO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def tokenize_data(df, model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    inputs = tokenizer(df[\"input\"].tolist(), padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "    targets = tokenizer(df[\"target\"].tolist(), padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
        "    return inputs, targets, tokenizer\n"
      ],
      "metadata": {
        "id": "TrW5MqhGvA13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear Dataset PyTorch"
      ],
      "metadata": {
        "id": "pJpHU6-QvIwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpiderDataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
        "            \"labels\": self.targets[\"input_ids\"][idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Dp2gr0RMvJwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurar y Entrenar los Modelos T5-LM-Large-text2sql-spider"
      ],
      "metadata": {
        "id": "hMgAChYXvN8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Modelos en Hugging Face\n",
        "models = {\n",
        "    \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\",\n",
        "    #\"BART-LARGE-NL2SQL\": \"SwastikM/bart-large-nl2sql\",\n",
        "    #\"NL2SQL-StarCoder-15B\": \"gabrielpondc/NL2SQL-StarCoder-15B\",\n",
        "  #  \"AutoSQL-nl2sql-8b\": \"xbrain/AutoSQL-nl2sql-1.0-8b\",\n",
        "   # \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\"\n",
        "}\n",
        "\n",
        "# Entrenar cada modelo\n",
        "for model_name, model_path in models.items():\n",
        "    print(f\"\\nðŸ”µ Entrenando {model_name}...\\n\")\n",
        "\n",
        "    # Tokenizar datos\n",
        "    train_inputs, train_targets, tokenizer = tokenize_data(train_df, model_path)\n",
        "    val_inputs, val_targets, _ = tokenize_data(val_df, model_path)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_dataset = SpiderDataset(train_inputs, train_targets)\n",
        "    val_dataset = SpiderDataset(val_inputs, val_targets)\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    # Configurar entrenamiento\n",
        "    training_args = TrainingArguments(\n",
        "        #Fine Tune: se agrega fp16=True para reducir memoria y mejorar el entrenamiento\n",
        "        fp16=True,\n",
        "        output_dir=f\"./{model_name}_spider\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #Fine Tune: Incrementamos el trainin batch y eval batch de 4 a 8 para mejorar el entrenamiento\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        #Fine Tune reducimos el learning_rate=3e-5,para hacerlo mas estable\n",
        "        learning_rate=1e-5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True, #Requerido para Early Stopping\n",
        "        #Aumentamos cantidad de epocas de 3 a 5, ahora incrementamos a 7\n",
        "        num_train_epochs=7,\n",
        "        logging_dir=f\"./logs/{model_name}\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        #optimizers=(trainer.optimizer, lr_scheduler)\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "\n",
        "    # Iniciar entrenamiento\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar modelo en Google Drive\n",
        "    save_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"âœ… Modelo {model_name} guardado en {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KDBpU6hzvOk_",
        "outputId": "26e408e0-9170-4c51-d61e-57c88a3c9968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”µ Entrenando T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6125' max='6125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6125/6125 21:08, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.464700</td>\n",
              "      <td>0.699342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.729700</td>\n",
              "      <td>0.609927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.601500</td>\n",
              "      <td>0.576252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>0.554152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.525200</td>\n",
              "      <td>0.551633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.510700</td>\n",
              "      <td>0.544431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.502800</td>\n",
              "      <td>0.541947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Modelo T5-Small-NL2SQL guardado en /content/drive/My Drive/spider_models_fine_Tuned/T5-Small-NL2SQL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Modelos en Hugging Face\n",
        "models = {\n",
        "    \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\",\n",
        "    #\"BART-LARGE-NL2SQL\": \"SwastikM/bart-large-nl2sql\",\n",
        "    #\"NL2SQL-StarCoder-15B\": \"gabrielpondc/NL2SQL-StarCoder-15B\",\n",
        "  #  \"AutoSQL-nl2sql-8b\": \"xbrain/AutoSQL-nl2sql-1.0-8b\",\n",
        "   # \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\"\n",
        "}\n",
        "\n",
        "# Entrenar cada modelo\n",
        "for model_name, model_path in models.items():\n",
        "    print(f\"\\nðŸ”µ Entrenando {model_name}...\\n\")\n",
        "\n",
        "    # Tokenizar datos\n",
        "    train_inputs, train_targets, tokenizer = tokenize_data(train_df, model_path)\n",
        "    val_inputs, val_targets, _ = tokenize_data(val_df, model_path)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_dataset = SpiderDataset(train_inputs, train_targets)\n",
        "    val_dataset = SpiderDataset(val_inputs, val_targets)\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    # Configurar entrenamiento\n",
        "    training_args = TrainingArguments(\n",
        "        #Fine Tune: se agrega fp16=True para reducir memoria y mejorar el entrenamiento\n",
        "        fp16=True,\n",
        "        output_dir=f\"./{model_name}_spider\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #Fine Tune: Incrementamos el trainin batch y eval batch de 4 a 8 para mejorar el entrenamiento\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        #Fine Tune reducimos el learning_rate=3e-5,para hacerlo mas estable\n",
        "        learning_rate=1e-5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True, #Requerido para Early Stopping\n",
        "        #Aumentamos cantidad de epocas a 9\n",
        "        num_train_epochs=9,\n",
        "        logging_dir=f\"./logs/{model_name}\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        #optimizers=(trainer.optimizer, lr_scheduler)\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "\n",
        "    # Iniciar entrenamiento\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar modelo en Google Drive\n",
        "    save_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"âœ… Modelo {model_name} guardado en {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ajY3dkJo6UsX",
        "outputId": "fcaac19f-0604-4c98-daef-dd0452328550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”µ Entrenando T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7875/7875 27:07, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.461600</td>\n",
              "      <td>0.697234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.722600</td>\n",
              "      <td>0.610363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.588800</td>\n",
              "      <td>0.570234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.534300</td>\n",
              "      <td>0.543981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.506500</td>\n",
              "      <td>0.543631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.486200</td>\n",
              "      <td>0.536489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.470900</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.455200</td>\n",
              "      <td>0.520637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>0.519721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Modelo T5-Small-NL2SQL guardado en /content/drive/My Drive/spider_models_fine_Tuned/T5-Small-NL2SQL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "# Modelos en Hugging Face\n",
        "models = {\n",
        "    \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\",\n",
        "    #\"BART-LARGE-NL2SQL\": \"SwastikM/bart-large-nl2sql\",\n",
        "    #\"NL2SQL-StarCoder-15B\": \"gabrielpondc/NL2SQL-StarCoder-15B\",\n",
        "  #  \"AutoSQL-nl2sql-8b\": \"xbrain/AutoSQL-nl2sql-1.0-8b\",\n",
        "   # \"T5-Small-NL2SQL\": \"Shritama/t5-small-finetuned-nl2sql\"\n",
        "}\n",
        "\n",
        "# Entrenar cada modelo\n",
        "for model_name, model_path in models.items():\n",
        "    print(f\"\\nðŸ”µ Entrenando {model_name}...\\n\")\n",
        "\n",
        "    # Tokenizar datos\n",
        "    train_inputs, train_targets, tokenizer = tokenize_data(train_df, model_path)\n",
        "    val_inputs, val_targets, _ = tokenize_data(val_df, model_path)\n",
        "\n",
        "    # Crear dataset\n",
        "    train_dataset = SpiderDataset(train_inputs, train_targets)\n",
        "    val_dataset = SpiderDataset(val_inputs, val_targets)\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "    # Configurar entrenamiento\n",
        "    training_args = TrainingArguments(\n",
        "        #Fine Tune: se agrega fp16=True para reducir memoria y mejorar el entrenamiento\n",
        "        fp16=True,\n",
        "        output_dir=f\"./{model_name}_spider\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        #Fine Tune: Incrementamos el trainin batch y eval batch de 4 a 8 para mejorar el entrenamiento\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        #Fine Tune reducimos el learning_rate=3e-5,para hacerlo mas estable\n",
        "        learning_rate=1e-5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True, #Requerido para Early Stopping\n",
        "        #Aumentamos cantidad de epocas a 15\n",
        "        num_train_epochs=15,\n",
        "        logging_dir=f\"./logs/{model_name}\",\n",
        "        save_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        #optimizers=(trainer.optimizer, lr_scheduler)\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "\n",
        "    # Iniciar entrenamiento\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar modelo en Google Drive\n",
        "    save_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"âœ… Modelo {model_name} guardado en {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "rKdPHs75EatR",
        "outputId": "75506743-ab18-4527-dd83-592626a024b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”µ Entrenando T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10500' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10500/13125 36:14 < 09:03, 4.83 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.458800</td>\n",
              "      <td>0.693660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.714300</td>\n",
              "      <td>0.604788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.574300</td>\n",
              "      <td>0.563985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.514800</td>\n",
              "      <td>0.540948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.484700</td>\n",
              "      <td>0.534806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>0.521794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.437100</td>\n",
              "      <td>0.514586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.414500</td>\n",
              "      <td>0.504611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.406200</td>\n",
              "      <td>0.496596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.399700</td>\n",
              "      <td>0.488796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.390200</td>\n",
              "      <td>0.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.378600</td>\n",
              "      <td>0.489362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Modelo T5-Small-NL2SQL guardado en /content/drive/My Drive/spider_models_fine_Tuned/T5-Small-NL2SQL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probar el Modelo Entrenado"
      ],
      "metadata": {
        "id": "Pd4Eml6n4WOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu datasets torch tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-e9kKkXRB1W",
        "outputId": "b6af4c14-0343-40e6-c8de-62c4ccdb4378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# ðŸ“Œ Lista de modelos a evaluar\n",
        "models_to_test = {\n",
        "\n",
        "    \"T5-Small-NL2SQL\": \"/content/drive/MyDrive/spider_models_fine_Tuned/T5-Small-NL2SQL\",\n",
        "\n",
        "}\n",
        "\n",
        "# ðŸ“Œ Diccionario para almacenar modelos y tokenizers\n",
        "models_dict = {}\n",
        "\n",
        "for model_name, model_path in models_to_test.items():\n",
        "    try:\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        models_dict[model_name] = {\"model\": model, \"tokenizer\": tokenizer}\n",
        "        print(f\"âœ… {model_name} cargado correctamente.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error al cargar {model_name}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTYtWID9RZJo",
        "outputId": "7a85cf56-d653-44eb-eb3f-4ad2e2950a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… T5-Small-NL2SQL cargado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probar el Modelo"
      ],
      "metadata": {
        "id": "WQBeEoSzSUQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar un modelo entrenado\n",
        "model_name = \"T5-Small-NL2SQL\"\n",
        "model_path = f\"/content/drive/My Drive/spider_models_fine_Tuned/{model_name}\"\n",
        "\n",
        "# Cargar modelo y tokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# FunciÃ³n de inferencia\n",
        "def generate_sql(question):\n",
        "    input_text = f\"Translate to SQL: {question}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generar SQL\n",
        "    output = model.generate(**inputs)\n",
        "    sql_query = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Prueba con una pregunta nueva\n",
        "#question = \"Â¿CuÃ¡ntos empleados hay en la base de datos?\"\n",
        "question = \"count of employees?\"\n",
        "sql_generated = generate_sql(question)\n",
        "\n",
        "print(\"Pregunta:\", question)\n",
        "print(\"SQL Generado:\", sql_generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNstqebTRvvg",
        "outputId": "f60cc85e-e0ba-4dee-d2b5-d135bc2a4799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: count of employees?\n",
            "SQL Generado: SELECT count(*) FROM employees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar Predicciones SQL para ValidaciÃ³n"
      ],
      "metadata": {
        "id": "DXnHnyyRSdGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "SPIDER_PATH = \"/content/drive/My Drive/spider\"\n",
        "\n",
        "# ðŸ“Œ Cargar datos de validaciÃ³n de Spider\n",
        "with open(f\"{SPIDER_PATH}/dev.json\", \"r\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "# ðŸ“Œ Extraer preguntas y sus SQL correctos\n",
        "questions = [item[\"question\"] for item in val_data]\n",
        "true_sql = [item[\"query\"] for item in val_data]\n",
        "\n",
        "# ðŸ“Œ FunciÃ³n para generar SQL con cada modelo\n",
        "def generate_sql(model, tokenizer, question):\n",
        "    input_text = f\"Translate to SQL: {question}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    output = model.generate(\n",
        "        **inputs, max_length=128, temperature=0.7, top_p=0.9, num_return_sequences=1, repetition_penalty=1.2\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# ðŸ“Œ Generar consultas SQL con cada modelo\n",
        "predictions = {}\n",
        "for model_name, data in models_dict.items():\n",
        "    print(f\"\\nðŸš€ Generando SQL con {model_name}...\\n\")\n",
        "    model = data[\"model\"]\n",
        "    tokenizer = data[\"tokenizer\"]\n",
        "    predictions[model_name] = [generate_sql(model, tokenizer, q) for q in questions]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0nzeQBeSdjn",
        "outputId": "8dede970-156e-4a76-d359-fa9184523b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Generando SQL con T5-Small-NL2SQL...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar Modelo"
      ],
      "metadata": {
        "id": "VOCJtD3QU0i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfnTJlxjUuPY",
        "outputId": "979d4e53-a759-4a69-c8ab-409805a4bb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import sqlite3\n",
        "from tabulate import tabulate\n",
        "\n",
        "# ðŸ“Œ Cargar mÃ©tricas BLEU\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ðŸ“Œ FunciÃ³n para calcular Exact Match\n",
        "def exact_match(pred, true):\n",
        "    return int(pred.strip().lower() == true.strip().lower())\n",
        "\n",
        "# ðŸ“Œ FunciÃ³n para ejecutar consultas SQL en SQLite\n",
        "def execute_sql(query, conn):\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(query)\n",
        "        return cursor.fetchall()\n",
        "    except Exception as e:\n",
        "        return None  # Si la consulta es invÃ¡lida, devuelve None\n",
        "\n",
        "# ðŸ“Œ FunciÃ³n para calcular Execution Accuracy\n",
        "def execution_accuracy(predictions, references, conn):\n",
        "    correct = sum(1 for pred, ref in zip(predictions, references) if execute_sql(pred, conn) == execute_sql(ref, conn))\n",
        "    return (correct / len(references)) * 100\n",
        "\n",
        "# ðŸ“Œ Crear una base de datos en memoria para evaluar Execution Accuracy\n",
        "conn = sqlite3.connect(\":memory:\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# ðŸš€ SimulaciÃ³n de una base de datos (AsegÃºrate de usar una DB real en producciÃ³n)\n",
        "cursor.execute(\"CREATE TABLE employees (id INTEGER, name TEXT, salary INTEGER)\")\n",
        "cursor.executemany(\"INSERT INTO employees (id, name, salary) VALUES (?, ?, ?)\", [\n",
        "    (1, \"Alice\", 50000),\n",
        "    (2, \"Bob\", 60000),\n",
        "    (3, \"Charlie\", 70000)\n",
        "])\n",
        "conn.commit()\n",
        "\n",
        "# ðŸ“Œ Evaluar cada modelo\n",
        "results = []\n",
        "\n",
        "for model_name in models_dict.keys():\n",
        "    pred_sql = predictions[model_name]\n",
        "\n",
        "    # ðŸ“Œ Calcular BLEU Score\n",
        "    bleu_score = bleu_metric.compute(predictions=pred_sql, references=[[x] for x in true_sql])[\"score\"]\n",
        "\n",
        "    # ðŸ“Œ Calcular Exact Match (EM)\n",
        "    em_score = sum(exact_match(pred_sql[i], true_sql[i]) for i in range(len(true_sql))) / len(true_sql)\n",
        "\n",
        "    # ðŸ“Œ Calcular Execution Accuracy\n",
        "    exec_acc = execution_accuracy(pred_sql, true_sql, conn)\n",
        "\n",
        "    results.append([model_name, round(bleu_score, 2), round(em_score * 100, 2), round(exec_acc, 2)])\n",
        "\n",
        "# ðŸ“Œ Mostrar Resultados en Tabla\n",
        "print(\"\\nðŸ“Š **ComparaciÃ³n de MÃ©tricas**\\n\")\n",
        "print(tabulate(results, headers=[\"Modelo\", \"BLEU Score\", \"Exact Match (%)\", \"Execution Accuracy (%)\"], tablefmt=\"grid\"))\n",
        "\n",
        "# ðŸ“Œ Cerrar la conexiÃ³n con la base de datos\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgj09bKp7qi-",
        "outputId": "4ea05c84-2551-421a-881b-23994449ad0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š **ComparaciÃ³n de MÃ©tricas**\n",
            "\n",
            "+-----------------+--------------+-------------------+--------------------------+\n",
            "| Modelo          |   BLEU Score |   Exact Match (%) |   Execution Accuracy (%) |\n",
            "+=================+==============+===================+==========================+\n",
            "| T5-Small-NL2SQL |        21.46 |              1.35 |                    99.81 |\n",
            "+-----------------+--------------+-------------------+--------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ BLEU Score (21.46) es aceptable, pero bajo comparado con modelos mÃ¡s avanzados (35+).\n",
        "\n",
        "2ï¸âƒ£ Exact Match (1.35%) es extremadamente bajo, lo que indica que el modelo rara vez genera consultas idÃ©nticas a las referencias.\n",
        "\n",
        "3ï¸âƒ£ Execution Accuracy (99.81%) es prÃ¡cticamente perfecto, lo que significa que las consultas generadas producen los mismos resultados que las referencias en la base de datos.\n",
        "\n",
        "âœ… El modelo estÃ¡ generalizando bien y generando SQL vÃ¡lido.\n",
        "âš  No es necesario obsesionarse con Exact Match, porque la consulta puede ser diferente en texto pero funcionalmente correcta."
      ],
      "metadata": {
        "id": "McqcBNI_jeuW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "miAxs8I5AfNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tw5vrOq_AeQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}